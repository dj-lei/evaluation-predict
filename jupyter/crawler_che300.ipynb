{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import redis\n",
    "import scrapy\n",
    "import datetime\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from lxml import etree\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from selenium import webdriver\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "pool = redis.ConnectionPool(host='172.17.0.2', port=6379, decode_responses=True, db=1, password='De32wsxC')\n",
    "redis_con = redis.Redis(connection_pool=pool)\n",
    "\n",
    "PRODUCE_DB_ADDR_OUTTER = '172.17.0.4'\n",
    "PRODUCE_DB_USER = 'root'\n",
    "PRODUCE_DB_PASSWD = '123456'\n",
    "\n",
    "LCCAL_ENGINE = 'mysql+pymysql://'+PRODUCE_DB_USER+':'+PRODUCE_DB_PASSWD+'@'+PRODUCE_DB_ADDR_OUTTER+'/temp?charset=utf8'\n",
    "engine = create_engine(LCCAL_ENGINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_recognition(image,net):\n",
    "    orig = image.copy()\n",
    "    (origH, origW) = image.shape[:2]\n",
    "\n",
    "    # extract the actual padded ROI\n",
    "    roi = orig[0:origH, 0:origW]\n",
    "    config = (\"-l eng --oem 1 --psm 7\")\n",
    "    text = pytesseract.image_to_string(roi, config=config)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def assemble_series_list(brand):\n",
    "    \"\"\"\n",
    "    组合series list\n",
    "    \"\"\"\n",
    "    # 清空数据库\n",
    "    redis_con.flushdb()\n",
    "    for i in range(0, len(brand)):\n",
    "        url = 'https://ssl-meta.che300.com/meta/series/series_brand' + str(brand['brand_id'][i]) + '.json?v=1561446955'\n",
    "        redis_con.sadd('che300_series_list', url)\n",
    "        \n",
    "def assemble_detail_list(model):\n",
    "    \"\"\"\n",
    "    组合detail list\n",
    "    \"\"\"\n",
    "    # 清空数据库\n",
    "    redis_con.flushdb()\n",
    "    for i in range(0, len(model)):\n",
    "        url = 'https://ssl-meta.che300.com/meta/model/model_series' + str(model['series_id'][i]) + '.json?v=1561446955'\n",
    "        redis_con.sadd('che300_detail_list', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "\n",
    "urls = {\n",
    "    'home': 'https://www.che300.com/pinggu?from=bd_seo&rt=1561513934702'\n",
    "}\n",
    "driver.get(urls['home'])\n",
    "driver.find_elements_by_xpath(\"//div[@class='select_box']\")[0].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一.品牌抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brand = pd.DataFrame([],columns=['brand_id','brand_name','first_letter'])\n",
    "elem=driver.find_elements_by_xpath(\"//p[@class='pinpailist list_1']\")\n",
    "\n",
    "for i in range(0,len(elem)):\n",
    "    brand.loc[i,'brand_id'] = elem[i].get_attribute('id')\n",
    "    brand['brand_name'][i] = elem[i].text\n",
    "    brand['first_letter'][i] = elem[i].get_attribute('rel')\n",
    "brand.to_csv('./brand_che300.csv', index=False)\n",
    "assemble_series_list(brand)\n",
    "model = pd.DataFrame([],columns=['brand_id','series_id','series_name','is_green','series_group_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二.车型抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = redis_con.spop('che300_series_list')\n",
    "        if url == None:\n",
    "            break\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "        count_series = len(driver.find_elements_by_xpath(\"//span[@class='treeLabel objectLabel']\"))\n",
    "        if count_series == 0:\n",
    "            continue\n",
    "\n",
    "        result = driver.find_elements_by_xpath(\"//span[@class='objectBox objectBox-string']\")\n",
    "        temp = pd.DataFrame([],columns=['brand_id','series_id','series_name','is_green','series_group_name'])\n",
    "        for i in range(0,count_series):\n",
    "            temp.loc[i,'brand_id'] = int(re.findall('brand(.*)\\.json',url)[0])\n",
    "            temp.loc[i,'series_id'] = result[i*4].text.replace(\"\\\"\",\"\")\n",
    "            temp.loc[i,'series_name'] = result[i*4+1].text.replace(\"\\\"\",\"\")\n",
    "            temp.loc[i,'is_green'] = result[i*4+2].text.replace(\"\\\"\",\"\")\n",
    "            temp.loc[i,'series_group_name'] = result[i*4+3].text.replace(\"\\\"\",\"\")\n",
    "        model = model.append(temp,sort=False).reset_index(drop=True)\n",
    "    except Exception:\n",
    "        redis_con.sadd('che300_series_list', url)\n",
    "        raise Exception(traceback.format_exc())\n",
    "model.to_csv('./model_che300.csv', index=False)\n",
    "assemble_detail_list(model)\n",
    "detail = pd.DataFrame([],columns=['series_id','model_id','model_name','model_price','model_year','min_reg_year',\n",
    "                                  'max_reg_year','liter','liter_type','gear_type','discharge_standard','is_green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三.款型抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemble_detail_list(model)\n",
    "detail = pd.DataFrame([],columns=['series_id','model_id','model_name','model_price','model_year','min_reg_year',\n",
    "                                  'max_reg_year','liter','liter_type','gear_type','discharge_standard','is_green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefox_profile = webdriver.FirefoxProfile()\n",
    "firefox_profile.set_preference('permissions.default.stylesheet', 2)\n",
    "firefox_profile.set_preference('permissions.default.image', 2)\n",
    "firefox_profile.set_preference('devtools.jsonview.enabled', 'false')\n",
    "\n",
    "driver = webdriver.Firefox(firefox_profile=firefox_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = redis_con.spop('che300_detail_list')\n",
    "        if url == None:\n",
    "            break\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "        result = driver.find_elements_by_xpath(\"//pre\")[0].text\n",
    "        result = eval(result)\n",
    "        count_details = len(result)\n",
    "        if count_details == 0:\n",
    "            continue\n",
    "\n",
    "        temp = pd.DataFrame([],columns=['series_id','model_id','model_name','model_price','model_year','min_reg_year',\n",
    "                                  'max_reg_year','liter','liter_type','gear_type','discharge_standard','is_green'])\n",
    "        for i in range(0,count_details):\n",
    "            temp.loc[i,'series_id'] = int(re.findall('series(.*)\\.json',url)[0])\n",
    "            temp.loc[i,'model_id'] = result[i]['model_id']\n",
    "            temp.loc[i,'model_name'] = result[i]['model_name']\n",
    "            temp.loc[i,'model_price'] = result[i]['model_price']\n",
    "            temp.loc[i,'model_year'] = result[i]['model_year']\n",
    "            temp.loc[i,'min_reg_year'] = result[i]['min_reg_year']\n",
    "            temp.loc[i,'max_reg_year'] = result[i]['max_reg_year']\n",
    "            temp.loc[i,'liter'] = result[i]['liter']\n",
    "            temp.loc[i,'liter_type'] = result[i]['liter_type']\n",
    "            temp.loc[i,'gear_type'] = result[i]['gear_type']\n",
    "            temp.loc[i,'discharge_standard'] = result[i]['discharge_standard']\n",
    "            temp.loc[i,'is_green'] = result[i]['is_green']\n",
    "        detail = detail.append(temp,sort=False).reset_index(drop=True)\n",
    "    except Exception:\n",
    "        redis_con.sadd('che300_detail_list', url)\n",
    "        raise Exception(traceback.format_exc())\n",
    "detail.to_csv('./detail_che300.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = pd.read_csv('./brand_che300.csv')\n",
    "model = pd.read_csv('./model_che300.csv')\n",
    "detail = pd.read_csv('./detail_che300.csv')\n",
    "\n",
    "model = model.merge(brand,how='left',on=['brand_id'])\n",
    "detail = detail.merge(model.drop(['is_green'],axis=1),how='left',on=['series_id'])\n",
    "detail.to_csv('/home/ml/ProgramProjects/detail_match/jupyter/detail_che300.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四.估值抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7904\n",
      "582\n",
      "7322\n"
     ]
    }
   ],
   "source": [
    "def assemble_valute_detail_list(df):\n",
    "    url = 'https://www.che300.com/pinggu/v11c125m'+str(int(df['model_id']))+'r'+str(df['online_year'])+'-3'+'g'+str(df['mile'])+'?click=homepage&rt=1561682411644'\n",
    "    redis_con.sadd('che300_valute_detail_list', url)\n",
    "    return url\n",
    "\n",
    "che300_match_result = pd.read_csv('./che300_match_result.csv')\n",
    "che300_match_result = che300_match_result.loc[:,['model_id','origin_name','detail_slug','cos_similar']]\n",
    "\n",
    "car_autohome_all = pd.read_csv('../tmp/train/car_autohome_all.csv')\n",
    "car_autohome_all['used_years'] = datetime.datetime.now().year - car_autohome_all['online_year']\n",
    "car_autohome_all.loc[(car_autohome_all['used_years'] < 0), 'used_years'] = 0\n",
    "car_autohome_all = car_autohome_all.sort_values(by=['brand_slug', 'model_slug', 'online_year', 'price_bn']).reset_index(drop=True)\n",
    "\n",
    "at = car_autohome_all.loc[(car_autohome_all['control'] == '自动'),:].reset_index(drop=True)\n",
    "mt = car_autohome_all.loc[(car_autohome_all['control'] == '手动'),:].reset_index(drop=True)\n",
    "\n",
    "# 取低配数据\n",
    "at_low_config_car = at.loc[at.groupby(['brand_slug', 'model_slug', 'online_year']).price_bn.idxmin(), :].reset_index(drop=True)\n",
    "mt_low_config_car = mt.loc[mt.groupby(['brand_slug', 'model_slug', 'online_year']).price_bn.idxmin(), :].reset_index(drop=True)\n",
    "low_config_car = at_low_config_car.append(mt_low_config_car,sort=False)\n",
    "print(len(low_config_car))\n",
    "low_config_car = low_config_car.merge(che300_match_result,how='left',on=['detail_slug'])\n",
    "\n",
    "miss_match = low_config_car.loc[(low_config_car['model_id'].isnull()),:].reset_index(drop=True)\n",
    "miss_match.to_csv('./che300_miss_match.csv',index=False)\n",
    "print(len(miss_match))\n",
    "\n",
    "low_config_car = low_config_car.loc[(low_config_car['model_id'].notnull()),:].reset_index(drop=True)\n",
    "low_config_car = low_config_car.loc[low_config_car.groupby(['detail_slug']).cos_similar.idxmax(), :].reset_index(drop=True)\n",
    "print(len(low_config_car))\n",
    "\n",
    "low_config_car['mile'] = low_config_car['used_years'] * 2\n",
    "low_config_car.loc[(low_config_car['used_years'] == 0),'mile'] = 0.5\n",
    "low_config_car['url'] = low_config_car.apply(assemble_valute_detail_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.get('https://www.che300.com/pinggu?from=bd_seo&rt=1561680317573')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Traceback (most recent call last):\n  File \"<ipython-input-165-f66222bac725>\", line 16, in <module>\n    raise Exception('异常')\nException: 异常\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-f66222bac725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_up\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'异常'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: 异常",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-f66222bac725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mredis_con\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msadd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'che300_valute_detail_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mvaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./che300_valuate.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Traceback (most recent call last):\n  File \"<ipython-input-165-f66222bac725>\", line 16, in <module>\n    raise Exception('异常')\nException: 异常\n"
     ]
    }
   ],
   "source": [
    "# load the pre-trained EAST text detector\n",
    "net = cv2.dnn.readNet('opencv-text-recognition/frozen_east_text_detection.pb')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        url = redis_con.spop('che300_valute_detail_list')\n",
    "        if url == None:\n",
    "            break\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        sp_up = driver.find_elements_by_xpath(\"//ul[@class='sp-value clearfix']/li/span/img\")\n",
    "        sp_bottom = driver.find_elements_by_xpath(\"//div[@class='sp-price']/ul[@class='sp-bottom']/li/img\")\n",
    "        \n",
    "        if len(sp_up) != 9:\n",
    "            raise Exception('异常')\n",
    "        \n",
    "        up_price_recognition = []\n",
    "        bottom_price_recognition = []\n",
    "        for i,img in enumerate(sp_up):\n",
    "            image = img.get_attribute('src').split('base64,')[1]\n",
    "            image = base64.b64decode(image)\n",
    "            image_result = open('images/up_'+str(i)+'.png', 'wb')\n",
    "            image_result.write(image)\n",
    "            image_result.flush()\n",
    "            image_result.close()\n",
    "            # load the input image and grab the image dimensions\n",
    "            image = cv2.imread('images/up_'+str(i)+'.png')\n",
    "            price = price_recognition(image,net)\n",
    "            up_price_recognition.append(float(price))\n",
    "\n",
    "        for i,img in enumerate(sp_bottom):\n",
    "            image = img.get_attribute('src').split('base64,')[1]\n",
    "            image = base64.b64decode(image)\n",
    "            image_result = open('images/bottom_'+str(i)+'.png', 'wb')\n",
    "            image_result.write(image)\n",
    "            image_result.flush()\n",
    "            image_result.close()\n",
    "            # load the input image and grab the image dimensions\n",
    "            image = cv2.imread('images/bottom_'+str(i)+'.png')\n",
    "            price = price_recognition(image,net)\n",
    "            bottom_price_recognition.append(float(price))\n",
    "    \n",
    "        temp = pd.DataFrame([],columns=['model_id','up_price','bottom_price'])\n",
    "        temp.loc[i,'model_id'] = str(int(re.findall('v11c125m(.*)r20',url)[0]))\n",
    "        temp.loc[i,'up_price'] = str(up_price_recognition)\n",
    "        temp.loc[i,'bottom_price'] = str(bottom_price_recognition)\n",
    "        temp.to_sql(name='che300_valuate', if_exists='append', con=engine, index=False)\n",
    "    except Exception:\n",
    "        redis_con.sadd('che300_valute_detail_list', url)\n",
    "        raise Exception(traceback.format_exc())\n",
    "valuate.to_csv('./che300_valuate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
